---
title: 《水浒传》人物出场统计
date: 2018-04-21 20:17:34
tags:
---

运用了 python 的 第三库 jieba 分词库, WordCloud 词云库, pyecharts 数据报表库   

<!-- more -->

```python
#《水浒传》 人物出场统计v2

import jieba
import json
from scipy.misc import imread
import time
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from pyecharts import Bar

# 用于加载本地文本为 list
def locallist(filepath):
    locattxt = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]
    return locattxt

# 文本分词
def getwords(originfile, selfdect): # originfile = '.\date\水浒传.txt',  selfdect= r".\date\jieba.txt"
    txt = open(originfile, 'r', encoding='utf-8').read();
    # 加载自定義字典
    jieba.load_userdict(selfdect)
    # jieba 分詞
    words = jieba.lcut(txt, cut_all=False);
    return words


# 去除无关的词并根据词频排序集合
def stopwords(stopwords, counts):
    for word in stopwords:
        del counts[word]
    items = list(counts.items());
    # 根据词频排序集合
    items.sort(key=lambda x: x[1], reverse=True)
    return items

#解析成 json 类型并写文件
def getjson(counts):
    wordjson = json.dumps((sorted(counts.items(), key=lambda x:x[1], reverse=True)), ensure_ascii=False)
    with open(r'.\date\wordjson.json', 'w+', encoding='utf-8') as f:
        f.write(wordjson)

# 打印
def showpirnt(items):
    for i in range(50):
        word, count = items[i]
        print('{0:^4}{1:<10}{2:>5}'.format(i + 1, word, count))

# 生成词云
def getwordcloud(imagepath, counts):
    #back_color = imread('F:\MoocPython\week06\image\bg.jpg')  # 解析该图片
    imagepath = imagepath + str(time.time())[-3:] + '.jpg' # 设置图片保存的路径
    wcimage = WordCloud(font_path=r".\font\msyh.ttf",
                        max_words=50,
                        height=600,
                        width=1200,
                        #background_color='white',
                        #mask=back_color
                         ).generate_from_frequencies(counts)
    plt.imshow(wcimage)
    plt.axis('off')
    plt.show()
    wcimage.to_file(imagepath) # 保存图片

# 生成柱形表
def changlist(jsondict, savepath='.\date\pycs', title='水浒传人物出场统计(50)'):# dict 数据 -> list(dict.keys()), list(dict.values())
    attr = []
    value = []
    for i in range(30):
        attr.append(list(jsondict.keys())[i])
    for i in range(30):
        value.append(list(jsondict.values())[i])
    attr = ['{}'.format(i) for i in attr]
    value = ['{}'.format(i) for i in value]
    bar = Bar(title)
    bar.add('', attr, value, is_label_show=True, is_datazoom_show=True)
    bar.render(path=savepath + str(time.time())[-3:] + '.html')

if __name__ == '__main__':
    words = getwords(str('.\date\水浒传.txt'), str(r'.\date\jieba.txt'))
    # 设置为字典类型
    counts = {}
    for word in words:
        if len(word) == 1:
            continue
        elif word == "宋江道" or word == "宋公明" or word == "宋江便" or word == "宋江见":
            rword = "宋江"
        elif word == "智深" or word == "和尚" or word == "提辖":
            rword = "鲁智深"
        elif word == "军师":
            rword == "吴用"
        elif word == "教头":
            rword == "林冲"
        elif word == "黑旋风":
            rword == "李逵"
        elif word == "戴宗道":
            rword == "戴宗"
        elif word == "柴大官人":
            rword == "柴进"
        else:
            rword = word
        # 利用字典统计词频
        counts[rword] = counts.get(rword, 0) + 1
    #print(counts)
    stopword = locallist(str('.\date\stopwords.txt'))
    items = stopwords(stopword, counts)
    showpirnt(items)
    getwordcloud(str('.\image\wcpic') ,counts)
    # 获取 json 数据
    jsontxt = open('.\date\wordjson.json', 'r', encoding='utf-8').read()
    txt = dict(json.loads(jsontxt))
    changlist(txt)
```